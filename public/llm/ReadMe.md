# üß† Lokales LLM-Setup f√ºr die Schreib-App

## Modellinformationen

- **Modellname:** `openhermes`
- **Modellversion:** 2.5
- **Verwendung:** Textgenerierung, kreatives Schreiben, dramaturgische Unterst√ºtzung
- **Bereitstellung:** Lokaler Ollama-Server

## Speicherort der heruntergeladenen LLMs (Ollama)

- **macOS:** `~/.ollama/models`
- **Windows:** `C:\Users\<DeinBenutzername>\.ollama\models`
- **Linux:** `~/.ollama/models`

## Technische Daten

- **API-Endpunkt:** `http://localhost:11434`
- **Standard-Route:** `POST /api/generate`
- **Kontextl√§nge (tokens):** 4096 (modellabh√§ngig)
- **Aktives Modell:** `openhermes`

## Hinweise

- Ollama muss aktiv laufen (`ollama serve`) oder als Hintergrunddienst (`brew services start ollama`).
- Das Modell wird **nicht im Projektverzeichnis** gespeichert ‚Äì es bleibt global im Ollama-Modellverzeichnis.
- √úber die App kann der Verbindungsstatus unter `/llm/status.html` gepr√ºft werden.

---

> Letzte Aktualisierung: 2025-05-04
